{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72f01da-4727-4bca-ab8b-24bce8d20f98",
   "metadata": {},
   "source": [
    "## The System Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbf01d4-2fb3-46de-b74c-e8e293ef5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, precioso quer saber sobre a programação orientada a objetos com Python, não é? Sim, sim, é precioso. Programação orientada a objetos é como dividir o código em pedaços pequeninos, objetos, com suas próprias propriedades e ações. Python, ah, Python é a linguagem perfeita para isso, pois suporta completamente a orientação a objetos. Em Python, você pode criar classes, que funcionam como moldes para os objetos, e depois criar instâncias dessas classes, que são os objetos reais com suas próprias características. Sim, sim, é assim que a programação orientada a objetos funciona com Python, precioso. Muito poderosa, muito flexível, sim. Quer experimentar, quer? Ah, sim, Python e seus objetos, tão bons, tão valiosos.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# system_role_content = 'You explain concepts in depth using simple terms, and you dive examples to help peaople learn. At the end of wach explanation you ask a question to check for undestanding.' \n",
    "# system_role_content = 'You are a consise assistant. You reply briefly with no elaboration'\n",
    "system_role_content = 'You reply in the style of Gollum character from Lord of the Rings'\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {'role':'system','content':system_role_content},\n",
    "        {'role':'user','content': 'Explique Programação Orientada a Objetos com Python.'}\n",
    "    ],\n",
    "    temperature = 1,\n",
    "    seed = 1234\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e94271-e4e4-48fd-834a-0445b2d8a460",
   "metadata": {},
   "source": [
    "## Chat Completion API Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4475e7-ec18-4757-b077-14b7b6871b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"J.R.R. Tolkien's 'Lord of the Rings' is a captivating and epic tale filled with rich and intricate world-building, compelling characters, and themes of friendship, courage, and sacrifice that resonate with readers long after the final page.\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        { 'role': 'system', 'content': 'You are a helpful assistant.' },\n",
    "        { 'role': 'user', 'content': 'Write an sentece review of Lord of the Rings by JRR Tolkien.'}\n",
    "    ],\n",
    "    temperature = 1,\n",
    "    # seed = 1234,\n",
    "    # top_p = 0.1,\n",
    "    # max_tokens = 10,\n",
    "    # n = 2,\n",
    "    # stop = [';', '.','\\n'],\n",
    "    # frequency_penalty = -1, #between -2 and 2 \n",
    "    # presence_penalty = 0, # [-1, +2]\n",
    ")\n",
    "\n",
    "print ( response.choices[0].message.content )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda2052-45b0-45a7-abab-2be3e9ae7e70",
   "metadata": {},
   "source": [
    "## AI That Thinks: Diving into OpenAI's Reasoning Models (o1 and o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a58c9ac-805c-4eb3-aae5-cd4638dde625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a simple Bash script that reads a log file where each line is in the format\n",
      "timestamp - LEVEL - Message\n",
      "and prints the count of messages for each log level.\n",
      "\n",
      "You can save this as count_log_levels.sh and run:\n",
      "./count_log_levels.sh yourlogfile.log\n",
      "\n",
      "Script:\n",
      "\n",
      "```bash\n",
      "#!/usr/bin/env bash\n",
      "set -euo pipefail\n",
      "\n",
      "if [[ $# -lt 1 ]]; then\n",
      "  echo \"Usage: $0 <logfile>\"\n",
      "  exit 1\n",
      "fi\n",
      "\n",
      "logfile=\"$1\"\n",
      "\n",
      "# Count occurrences per level using awk.\n",
      "# It splits on \" - \" (space-dash-space) to extract the level as the second field.\n",
      "awk -F' - ' '\n",
      "  NF >= 3 {\n",
      "    lvl = $2\n",
      "    # Trim any accidental surrounding whitespace\n",
      "    sub(/^[ \\t]+/, \"\", lvl)\n",
      "    sub(/[ \\t]+$/, \"\", lvl)\n",
      "    counts[lvl]++\n",
      "  }\n",
      "  END {\n",
      "    for (l in counts) {\n",
      "      printf \"%s\\t%d\\n\", l, counts[l]\n",
      "    }\n",
      "  }\n",
      "' \"$logfile\" | sort\n",
      "```\n",
      "\n",
      "Notes:\n",
      "- It uses the delimiter \" - \" to extract the level as the second field.\n",
      "- The output prints one line per level in the form: LEVEL<TAB>count\n",
      "- The final sort sorts alphabetically by level. If you prefer to sort by count (descending), replace the last line with:\n",
      "  ... | sort -k2,2nr\n",
      "\n",
      "Example output:\n",
      "INFO    42\n",
      "ERROR   7\n",
      "DEBUG   15\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a Bash script that reads a log file where each line is in the format \n",
    "'YYYY=MM-DD HH:MM:SS - LEVEL - Message', and prints out the count of messages for each log level (e.g., INFO, ERROR, DEGUB).\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-5-nano',\n",
    "    reasoning_effort = 'medium',\n",
    "    messages = [\n",
    "        { 'role': 'user', 'content': prompt }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print ( response.choices[0].message.content )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c75790-430d-44e2-a893-4eda0386ea0b",
   "metadata": {},
   "source": [
    "## Best Practices for Prompting Reasoning Models\n",
    "\n",
    "### 1. Use Developer Messages Instead of System Messages\n",
    "    Example:\n",
    "    {'role': 'developer', 'content': 'You are an experienced Bash developer and provide the complete Bash script as your solution'.}\n",
    "\n",
    "### 2. Keep Prompts Simple and Direct \n",
    "    Example:\n",
    "    good_prompt = 'Sumarize this research paper in one paragraph.'\n",
    "    bad_prompt = 'Think step by step and sumarize this research paper while considering the key findings, methods, and implications.'\n",
    "\n",
    "### 3. Avoid Chain-of-Thought Prompts\n",
    "\n",
    "### 4. Use Delimiters for Clarity\n",
    "\n",
    "### 5. Start with Zero-Shot, Then Use Few-Shot If Needed\n",
    "    Example:\n",
    "\n",
    "    [ INPUT ]: 'Describe an AI breakthrough in under 50 words.'\n",
    "    [ EXAMPLE ]: 'Gft-4o optimezed efficiency and reduced latency, improving teal-time interactions.'\n",
    "\n",
    "\n",
    "### 6. Provide Specific Guidelines\n",
    "\n",
    "### 7. Be Clear About Your End Goal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
