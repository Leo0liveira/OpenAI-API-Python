{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1847ce78",
   "metadata": {},
   "source": [
    "## Project - Animes Recomendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os \n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auth\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset into Pandas DataFrame\n",
    "\n",
    "df = pd.read_csv('./anime.csv')\n",
    "df.dropna(inplace=True)\n",
    "df = df.sort_values('synopsis', ascending=False).head(2000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Cost Calculator\n",
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "synopsis = list(df['synopsis'])\n",
    "total_tokens = sum([len(enc.encode(item)) for item in synopsis])\n",
    "print(f'Total Tokens:  {total_tokens}')\n",
    "cost = total_tokens * (0.0004/1000)\n",
    "print(f'Estimated cost in USD:  {cost:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcute the embedding and cache locally\n",
    "\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\"):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=model\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "\n",
    "def get_embeddings_and_save(embedding_cache_file):\n",
    "    texts = df[\"synopsis\"].astype(str).tolist()\n",
    "    embeddings = get_embeddings_batch(texts)\n",
    "\n",
    "    df[\"embedding\"] = embeddings\n",
    "    df.to_csv(embedding_cache_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29959739",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cache_file = \"anime_embeddings.csv\"\n",
    "get_embeddings_and_save(embedding_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Embeddings\n",
    "\n",
    "embedding_cache_file = 'anime_embeddings.csv'\n",
    "df_embeddings = pd.read_csv(embedding_cache_file)\n",
    "df_embeddings['embedding'] = df_embeddings['embedding'].apply(eval).apply(np.array)\n",
    "\n",
    "df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Recommendation from Title\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def get_recommendation_from_title(df_embeddings, title, k=5):\n",
    "\n",
    "    # Verifica se o título existe\n",
    "    if title not in df_embeddings[\"title\"].values:\n",
    "        print(\"Título não encontrado.\")\n",
    "        return None\n",
    "\n",
    "    # Pega embedding do anime escolhido\n",
    "    target_embedding = df_embeddings.loc[\n",
    "        df_embeddings[\"title\"] == title, \"embedding\"\n",
    "    ].values[0]\n",
    "\n",
    "    # Converter string para lista se estiver salvo como texto no CSV\n",
    "    if isinstance(target_embedding, str):\n",
    "        target_embedding = np.array(eval(target_embedding))\n",
    "    else:\n",
    "        target_embedding = np.array(target_embedding)\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for idx, row in df_embeddings.iterrows():\n",
    "        emb = row[\"embedding\"]\n",
    "\n",
    "        if isinstance(emb, str):\n",
    "            emb = np.array(eval(emb))\n",
    "        else:\n",
    "            emb = np.array(emb)\n",
    "\n",
    "        sim = cosine_similarity(target_embedding, emb)\n",
    "        similarities.append((row[\"title\"], sim))\n",
    "\n",
    "    # Ordena por similaridade (maior primeiro)\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Remove o próprio anime\n",
    "    similarities = [item for item in similarities if item[0] != title]\n",
    "\n",
    "    return similarities[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendation_from_title(df_embeddings, 'Boku', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
